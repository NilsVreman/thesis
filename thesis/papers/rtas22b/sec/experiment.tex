We evaluate here the performance of \tool{}.\footnote{All the reported experiments ran on an Intel Xeon E5-2620 v3 @ 2.40GHz CPU with 126GB RAM memory.}
First, we assess the scalability of the automaton generation, comparing \tool{} with the state-of-the-art \toolLinsenmayer{}~\cite{Linsenmayer:2017, Linsenmayer:2021}.
Then, we conduct a sensitivity analysis of \tool{} to determine which parameters affect the execution time for the automata generation in cases that cannot be handled with other tools, e.g., sets of weakly-hard constraints.
We provide results on how the type of constraints, maximum window length, and constraint set cardinality affect the computation time needed to generate the automaton.
Finally, we investigate the average cardinality of the dominant set as a function of the cardinality of a set of constraints.

% HERE FOR PLACING
\begin{figure*}[t]
    \input{\figdir/comparison.tex}
    \caption{Execution time comparison for \tAH{} and \tRH{} constraints with \tool{} and \toolLinsenmayer{}~\cite{Linsenmayer:2017} increasing the difference between window size and number of hits constrained.
        Baseline values are reported on top of the corresponding plots.}
    \label{fig:timing}
\end{figure*}

\subsection{Comparing \tool{} and \toolLinsenmayer{}}%
\label{sec:comparative_evaluation}%

The literature contribution that is closest to our research is \toolLinsenmayer{}~\cite{Linsenmayer:2017, Linsenmayer:2021}.
\toolLinsenmayer{}'s analysis of weakly-hard tasks is also based on the construction of automata.
While \toolLinsenmayer{} handles only one weakly-hard constraint at a time, it can construct the automaton that correspond to \tAH{} and \tRH{} constraints, making it the reference in terms of analysis capabilities.
\toolLinsenmayer{} is implemented in MATLAB, while \tool{} is implemented in Julia.
Hence, comparing the execution times of the two (on their own) is pointless.
Furthermore, we are more interested in assessing the scalability to an increase in the constraint window size than the absolute numbers for the execution times.
We therefore define a baseline case, for a fair comparison, i.e., the reported results are fractions and multiples of the baseline, which is different for each tool and constraint type.

To test the scalability of the automaton generation, we ask both \tool{} and \toolLinsenmayer{} to generate the automata that correspond to the \tAH{} $\binom{x}{k}$ and \tRH{} $\genfrac{<}{>}{0pt}{}{x}{k}$ constraints for $x \in \{1,2,\dots,10\}$, $k=x+i$ and $i \in \{0,1,\dots,10\}$.
We divide the obtained results by the baseline value, i.e., the execution time needed for the corresponding tool to generate the automaton for the given constraint type, $x=2$ and $k=4$.\footnote{The choice of the baseline case reflects the simplest constraint that is correctly handled by both \tool{} and \toolLinsenmayer{}. Comparing the methods, we unveiled that \toolLinsenmayer{} is unable to find an automaton for constraints in which $x=1$. The two plots for \toolLinsenmayer{} in Figure~\ref{fig:timing} do not contain results for $x=1$ (white filled markers) precisely due to this problem.}

Figure~\ref{fig:timing} shows the mean value of the execution time for the automaton generation, divided by the corresponding baseline value, using a logarithmic y-axis.
The baseline computation times for \tAH{} constraint are $3.7 \mu$s for \tool{} and   $32.4$ms for \toolLinsenmayer{}. On the contrary, for a \tRH{} constraint, the baseline computation time is $3.2 \mu$s for \tool{} and $17.7$ms for \toolLinsenmayer{}.
Due to the extensive computational time necessary to build the automata using \toolLinsenmayer{}, each automaton was built $30$ times (i.e., each point in the figure is the mean of $30$ executions).
\tool{} is significantly faster, thus, each automata was built $100\,000$ times to reduce the execution time variance.

\toolLinsenmayer{} represents a weakly-hard constraint with a slightly different, yet equivalent automaton to the one generated by \tool{}.
In particular, the automaton generated by \toolLinsenmayer{} has fewer vertices and weights on the edges encode the number of consecutive deadline misses allowed between the vertices.
Thus, a transition between two vertices in \toolLinsenmayer{} is not equivalent to one outcome (as for \tool{}), reducing flexibility, i.e., making it harder for example to automatically generate code to monitor the outcomes of task executions.
Multiple successive outcomes for each transition also complicate the handling of sets of weakly-hard constraints.
In terms of scalability, an automaton representation with fewer nodes may sound more efficient.
However, we show that \tool{} scales better than \toolLinsenmayer{} by more than an order of magnitude.
The baseline numbers show that \tool{} is also significantly faster in absolute terms.

Comparing the scalability of the two tools for \tAH{} constraints (leftmost plots), we observe that \tool{} is more than an order of magnitude faster than \toolLinsenmayer{}.
On the contrary, for \tRH{} constraints (rightmost plots), we experience a speedup of almost two orders of magnitude for high values of $i = k - x$.
The scalability of the \tRH{} constraints are further investigated in the following subsection.

\subsection{Evaluating \tRH{} constraints}
\label{sec:rowhit_evaluation}

In the previous subsection we discussed the scalability of \tool{} compared to the state-of-the-art.
Despite improvements of more than an order of magnitude (not considering the baseline), the time necessary to construct the automata for \tAH{} constraints grows rapidly with increasing window lengths.
Motivated by the ongoing discussion on the practical importance of consecutive deadline hits~\cite{Akesson:2020, Vreman:2021} and the scalability considerations presented in Section~\ref{sec:tool:scalability}, we now perform an extensive evaluation of the scalability of the \tRH{} constraints.

\begin{figure}[t]
    \input{\figdir/rowhit.tex}
    \caption{Mean execution time of the generation \tRH{} constraint automaton.}
    \label{fig:extensive_rowhit}
\end{figure}

Using \tool{}, we generate the automaton corresponding to the \tRH{} $\genfrac{<}{>}{0pt}{}{x}{k}$ constraints for $x \in \{1,2,\dots,15\}$, $k \in \{x,x+1,\dots,100\}$.
To the best of our knowledge, this is the first research work that generates automata representations of weakly-hard constraints with window lengths above $100$.
Figure~\ref{fig:extensive_rowhit} displays the mean execution time over $100$ executions for the automata generation using a logarithmic scale, showing a piecewise exponential growth of execution time with some jumps.
Despite having constraints with window lengths up to $k=100$, the worst reported execution time is below $7$ seconds; reinforcing the arguments in favour of using \tRH{} rather than \tAH{} constraints.

Another interesting consideration is related to the jumps in the execution time that each line shows when reaching certain values of $x$ and $k$.
This follows from the choice of using integers to represent words in \tool{}.
For constraints where $2x+k \geq 64$, $64$ bit integers are not enough to represent all sequences, and \tool{} consequently converts the sequence representation to big integers (using more than $64$ bits).
This representation requires additional resources (memory and computation), hence producing execution time jumps.

\begin{figure*}[t]
    \input{\figdir/set-comparison.tex}
    \caption{Execution time comparison for the generation of the automaton for sets of constraints with increasing maximum window sizes $\max k$.
        Average values are reported alongside the areas between minimum and maximum execution times.}
    \label{fig:set-comp}
\end{figure*}

\subsection{Analysing sets of weakly-hard constraints}
\label{sec:set_evaluation}

\tool{} is the first tool that provides the ability to analyse sets of weakly-hard constraints.
In the following we conduct a sensitivity analysis to assess the scalability of the automaton generation for a set of weakly hard constraints.
In particular, we are interested in finding how the window size affects the execution time of the tool, and how the composition of the set influences the execution time.

We randomise dominant sets of constraints, imposing that at least one of the constraints has a window size of $k_{\max} \in \left\{ 10,\,11,\,\dots,\,30 \right\}$.
We generate sets with either $\abs{\MDS} = 2$ or $\abs{\MDS} = 4$.
We allow these sets to include one \tRH{} constraint or none.
The results of our study are shown in Figure~\ref{fig:set-comp}.
For each of the values of $k_{\max}$ in the figure, we generate $50$ dominant sets $\MDS$.
The figure shows the average execution time in seconds (as a line) and the area representing the span between minimum and maximum execution time.

The first conclusion that we can draw is that the average execution times follow straight lines in a logarithmic scale, thus clearly pointing to the exponential time complexity inherent to expressive task models, such as the weakly-hard model~\cite{Stigge:2015}.

When the cardinality of the set $\abs{\MDS}$ increases (i.e., comparing the two leftmost and the two rightmost plots) the maximum execution time does not change significantly.
In fact, states that would have been reachable with fewer constraint become unreachable due to the additional constraints pruning the state-space.
However, we experience a slight reduction in the execution time's variance, which follows from the nature of the dominant set.
Comparing two dominant sets, $\MDS_1$ and $\MDS_2$, with the same $k_{\max}$: when $\abs{\MDS_1}=2$ and $\abs{\MDS_2}=4$, the set $\MDS_2$ must include less restrictive constraints (otherwise they would dominate the other constraints in the set).
Hence, the set $\MDS_2$ is less likely to be trivial to analyse.

Finally, including a \tRH{} constraint in the set $\MDS$ increases the execution time by an order of magnitude.
This follows from the complex interconnections between the \tRH{} and remaining weakly-hard constraints.
Particularly, for the \tAH{}, \tAM{}, and \tRM{} constraints it is sufficient to count the deadline hits of the jobs currently in the window; however, the \tRH{} constraints need to keep additional track of when they appeared.
This is further reinforced by the fact that when a dominant set includes a \tRH{} constraint, the other constraints in the set have to be very conservative in order to neither dominate nor be dominated by it.
However, we remark that \tool{} is able to generate an automaton for a set $\MDS$ of $4$ constraints with $k_{\max}=30$, including a \tRH{} constraint, in less than $200$ seconds.

\begin{figure}[t]
    \centering
    \input{\figdir/dominant-set-comparison.tex}
    \caption{Average cardinality of the dominant set $\MDS$ as a function of $\abs{\Lambda}$ with $k_{\max} = 100$ for $1000$ randomly generated constraint sets $\Lambda$.}
    \label{fig:dominant-set-comparison}
\end{figure}

\subsection{Determining the dominant constraint set}
\label{sec:set_dominant_cardinality}%

In Section~\ref{sec:set_evaluation} we investigated dominant sets $\MDS$ with cardinality $\abs{\MDS} \in \{2,4\}$.
Here we justify why this is a relevant benchmark despite the low cardinality.

We select a maximum window size $k_{\max} = 100$.
The window size is large enough that we can find an expressive variety of constraints without partial ordering.
We randomly generate sets $\Lambda$ containing $\abs{\Lambda} \in \{1,\dots,100\}$ constraints.
For each value of $\abs{\Lambda}$ we generate $1000$ different sets, excluding all the trivial constraints that would reduce to $\lhard$ and $\lweak$.
We then compute the dominant set $\MDS$ corresponding to each set.
Figure~\ref{fig:dominant-set-comparison} shows the average cardinality of $\MDS$ (solid line) and the experienced range (area).

As can be seen, most constraint sets reduce to dominant sets with cardinality less than $4$, thus motivating our investigation of the automaton generation execution time.
Generally, it is also interesting that additional constraints tends to reduce the cardinality of $\MDS$, after a peak is reached.
This is however not surprising seeing as adding constraints increases the chances of the added constraints being dominant over some of the constraints in the set.
