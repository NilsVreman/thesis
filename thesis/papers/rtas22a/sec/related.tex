In this section, we discuss the problem of implementing a control system, as defined in Section~\ref{sec:sys-model}, that is robust to deadline misses.
The problem has been investigated in the existing literature, and different methods have been proposed to solve it.
We offer a discussion on the scientific literature to identify the strengths and limitations of previous work and motivate the research problem studied in this paper.

\subsection{Related Work}
\label{sec:related}
The robustness of control algorithms to timing faults has been discussed both from the analysis and synthesis perspectives.
% control system analysis in presence of deadline misses
From the \emph{analysis} perspective, the literature proposes different methods to analyse the stability and performance of control systems in the presence of real-time faults.
The performance of different overrun handling strategies was discussed in the context of control systems in~\cite{Cervin:2005}.
Similar studies, in the context of networked control systems, were presented by~\cite{Schenato:2007} and~\cite{Vreman:2020}.
In~\cite{Frehse:2014}, the authors developed a network of hybrid automata to analyse the consequences of timing variations in control software.
The analysis of control systems under consecutive deadline misses was addressed in~\cite{Maggio:2020} and~\cite{Xiong:2007}, using respectively the joint spectral radius and Lyapunov theory.
Both~\cite{Hertneck:2021} and~\cite{Hertneck:2020} also leveraged Lyapunov theory to analyse nonlinear systems subject to network problems.
Shifting the focus from stability to performance,~\cite{Vreman:2021ecrts} analysed control systems subject to bursts of deadline misses.

From the \emph{synthesis} perspective, many works have studied overruns from a control and scheduling co-design perspective~\cite{Arzen:2000}. 
In~\cite{Schinkel:2006}, the authors designed state feedback controllers with time-varying gain, guaranteeing control performance under arbitrary period changes of the control task.
A similar approach was taken in~\cite{Ramanathan:1997}, where instead a weakly hard task model with known execution pattern was assumed.
The authors of~\cite{Chakraborty:2012} designed stabilising state feedback controllers with different controller gains depending on the system's time delay.
In~\cite{Pazzaglia:2019}, the authors used a probabilistic characterisation of the task model to develop state feedback controllers that are robust to deadline overruns.
Motivated by industrial practices,~\cite{Pazzaglia:2021} proposed the re-initialisation of the control task's period after the occurrence of overruns as well as the design of an adaptive control law.
%% the networked control systems perspective
In the field of networked control~\cite{Gupta:2010,Torngren:1998}, different works have proposed compensation schemes for jitter and dropped data packets~\cite{Nilsson:1998,Zhang:2001,Hespanha:2007}.
Within the same field,~\cite{Chakraborty:2014} proposed a control compensator design scheme for dropped packets under the weakly hard model that also guaranteed stability.
Similarly, \cite{Linsenmayer:2021} used design techniques from optimal control theory to co-design controllers.
\cite{Caccamo:2000} proposed to change the control task period according to the task execution time to improve schedulability and control performance.
Finally, several works discussed the trade-offs between schedulability and control performance~\cite{Crespo:1999,Eker:1999,Marti:2001,Caccamo:2002}.

This paper distinguishes itself from previous synthesis literature as it assumes that a linear controller has already been developed.
We propose an adaptive implementation of the control algorithm that does not require modifications to the system's design phase.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Research Problem Motivation}%
\label{sec:problem-form}%

Despite the considerable amount of prior research, we argue that existing design approaches to handling real-time faults in controllers suffer from at least one of the following limitations:
\begin{enumerate}[label=(\roman*)]
    \item Assumptions about static controller -- i.e., the controller cannot have any internal dynamics~\cite{Ramanathan:1997,Schinkel:2006,Zhang:2010,Chakraborty:2012,Chakraborty:2014,Linsenmayer:2017,Pazzaglia:2019,Maggio:2020}. 
    \item Complex co-design methodology, leading to conservative results -- i.e., a detailed system model and a large extra design effort are needed~\cite{Marti:2001,Schinkel:2006,Chakraborty:2012,Chakraborty:2014,Linsenmayer:2017,Pazzaglia:2021}.
    \item Increased runtime overhead -- i.e., the approach reduces the likelihood of completing the control execution within the same total time budget~\cite{Crespo:1999,Camacho:2010,Caccamo:2000}.
\end{enumerate}

The first limitation substantially narrows the applicability of the proposed design techniques, since the vast majority of real-world controllers include a dynamical part (e.g., an integrator to remove stationary errors, or a filter to estimate states or remove measurement noise).
It is important to study dynamic controllers as they are more severely affected by computational faults than static ones.
Intuitively, a static controller computes the control action $u$ solely based on the latest measurement, and is therefore always up to date with respect to the plant state.
In contrast, a dynamic controller computes $u$ also with respect to its internal state, which is computed on the base of older measurements.
When deadline misses occur, the controller state diverges from its desired value and degrades the control performance.
We support this intuition with a motivating example, considering a static controller and a comparable dynamic controller that includes a Kalman filter~\cite{AstWit:1984}.
The two controllers are designed to give similar performance under ideal conditions. 
The example shows that, while the static controller inherently provides robustness to deadline misses, the dynamic controller is significantly more sensitive.

\begin{example}[Motivating Example]%
    Consider the discrete-time LTI plant
     \begin{equation}
        \label{eq:example-plant}
        {\setlength\arraycolsep{3pt}
            \plant: \,\, \left\{
            \begin{aligned}
                x_{k+1} &= 
                \begin{bmatrix}
                    0 & 1 \\
                    -0.8 & 1.8
                \end{bmatrix}\,x_k + 
                \begin{bmatrix}
                    0 \\
                    1
                \end{bmatrix}\,u_k \\
                y_k &= x_k.
                 \end{aligned}
            \right.
        }
    \end{equation}   
    The control system's objective is to bring the state $x$ to zero.
    The plant $\plant$ consists of a stable pole and an integrator, which is compatible with several real-world applications, e.g., a cart on a rail or a joint of a robotic arm.
    To regulate the plant, we first consider the static controller $\ctrler_1$:
    \begin{equation*}
        {\setlength\arraycolsep{3pt}
        \begin{aligned}
            \ctrler_1: \,\, 
            u_{k+1} = 
            \begin{bmatrix}
                0.256 & -0.372
            \end{bmatrix}\,y_k.
        \end{aligned}
        }
    \end{equation*}
    The system is sampled and actuated using a sample time of $\Ts = 0.1$~s.
    We consider a scenario where the ECU executing the control law is experiencing sporadic CPU overloads, resulting in 25\% of the control jobs missing their corresponding deadlines.
    The initial state of the plant is $x_0 = [1, 1]^\T$, and we want the controller to move it to the final position $x_{f} = [0, 0]^\T$.
    In Figure~\ref{fig:lqr-lqg}, we show only the second component of the state vector $x$: the other component follows a very similar trajectory and is thus not plotted (for clarity).
    The behaviour of the plant controlled by $\ctrler_1$ without deadline overruns is the solid blue line.
    The dashed blue line instead corresponds to the state evolution in the presence of deadline misses.
    The control task overruns are marked by red crosses on the horizontal axis.
    Despite the missed job completions, the plant state recovers gracefully in very few steps, similarly to the ideal behaviour of the controller (in the absence of overruns).
    
    Practically, in all industrial applications, the control law $\ctrler_1$ would be preceded by a noise filter or a state estimator, which introduces dynamic behaviour in the controller. 
    Thus, we now consider the LQG controller $\ctrler_2$, which contains a Kalman filter designed to suppress noise: 
    \begin{equation*}
        %\label{eq:example-lqg}
        {\setlength\arraycolsep{3pt}
        \ctrler_2 : \left\{
        \begin{aligned}
            z_{k+1} &=
            \begin{bmatrix}
                -0.151 & 0.810 \\
                -0.711 & 1.206
            \end{bmatrix}\,z_k + 
            \begin{bmatrix}
                0.151 & 0.190 \\
                0.166 & 0.221
            \end{bmatrix}\,y_k \\
            u_{k+1} &=
            \begin{bmatrix}
                0.226 & -0.242
            \end{bmatrix}\,z_{k} +
            \begin{bmatrix}
                -0.023 & -0.034
            \end{bmatrix}\,y_k .
            \end{aligned}
        \right.}
    \end{equation*}
    The dashed green line in Figure~\ref{fig:lqr-lqg} shows the second component of the plant state $x$, controlled by the dynamic LQG controller $\ctrler_2$ and subject to the \emph{same} deadline misses as controller $\ctrler_1$.
    Comparing it to the ideal behaviour (solid green line), we observe a significant performance degradation compared to the static controller $\ctrler_1$.
    This showcases that dynamic controllers suffer more under sporadic overloads than static controllers.
\end{example}

\begin{figure}[t]
    \centerline{\input{\figdir/example-figs/lqr-lqg.tex}}
    \caption{The state $x_2$ corresponding to $\plant$ (sampled with $\Ts=0.1$s) being controlled by the static controller $\mathcal{C}_1$ (dashed blue) or the LQG controller $\mathcal{C}_2$ (dashed green) during an interval of sporadic overloads ($\times$).
        The corresponding ideal behaviours (system not subject to overruns) for the static (solid blue) and LQG (solid green) controllers are also plotted.
        The state $x_1$ follows a very similar trajectory and is not plotted for readability.}
    \label{fig:lqr-lqg}
\end{figure}

As for the second limitation listed above, introducing additional complexity for the gain of better performance is not always a desired design solution. 
The more convoluted the control design, the higher the design cost. 
This is a consequence of the increased development time needed to design the controller.
When the complexity of the controller increases, the cost of the system upkeep increases due to the expert knowledge required. 
The most popular controllers in industry are thus simple ones that still perform adequately (e.g., the PI controller~\cite{Sun:2016, Desborough:2002, Astrom:1984}).

Considering the third limitation, introducing additional overhead for fault-prone systems risks even more deadline misses. 
Depending on the plant or task model, there are cases where increasing the overhead might be acceptable, e.g., if deadline misses appear sporadically in bursts. 
However, for many task models, increasing the execution time after a deadline miss could have severe consequences, causing domino effects where subsequent jobs also miss their deadlines.

One major strength of many previously proposed fault-tolerant control design methods is that they can guarantee closed-loop stability under their respective fault and system models \cite{Schinkel:2006,Chakraborty:2012,Linsenmayer:2017,Linsenmayer:2020}. 
A majority of the studies investigate static controllers. 
However, in most real-world applications, the controllers are dynamic, e.g., an integrator, estimator, or filter is included in the loop.
The a priori guarantees provided for the static controller are hence lost.
Additionally, if the model of the controlled plant is unknown, no a priori stability guarantees could be achieved.
However, the resulting closed-loop system could be analysed a posteriori using any existing general method (see Section~\ref{sec:stability}).

\subsubsection*{Research Objective}
Tackling all the shortcomings mentioned above in a holistic manner is a complex task that does not necessarily have a general solution.
In this paper, we set out to derive a control adaptation strategy for \emph{dynamic} controllers to handle deadline misses whilst providing a \emph{simple} structure, \emph{minimal} overhead, and that does not reduce the system performance under ideal conditions.
To analyse the performance and robustness of the adaptive control strategy, we also seek to derive a stochastic mean-square analysis of the resulting closed-loop system to be performed a posteriori.
